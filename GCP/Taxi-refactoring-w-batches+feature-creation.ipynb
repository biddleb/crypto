{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2c. Refactoring to add batching and feature-creation </h1>\n",
    "\n",
    "In this notebook, we continue reading the same small dataset, but refactor our ML pipeline in two small, but significant, ways:\n",
    "<ol>\n",
    "<li> Refactor the input to read data in batches.\n",
    "<li> Refactor the feature creation so that it is not one-to-one with inputs.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.ml as ml\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "print tf.__version__\n",
    "#print ml.sdk_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Refactor the input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we are reading in batches.  Instead of using Pandas, we will add a filename queue to the TensorFlow graph.  This queue will be cycled through num_epochs times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_dataset(filename, num_epochs=None, batch_size=512, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "  def _input_fn():\n",
    "    input_file_names = tf.train.match_filenames_once(filename)\n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        input_file_names, num_epochs=num_epochs, shuffle=True)\n",
    "    reader = tf.TextLineReader()\n",
    "    _, value = reader.read_up_to(filename_queue, num_records=batch_size)\n",
    "\n",
    "    value_column = tf.expand_dims(value, -1)\n",
    "    columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "    features = dict(zip(CSV_COLUMNS, columns))\n",
    "    label = features.pop(LABEL_COLUMN)\n",
    "    return features, label\n",
    "\n",
    "  return _input_fn\n",
    "\n",
    "def get_train():\n",
    "  return read_dataset('../datasets/taxi-train.csv', num_epochs=100, mode=tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "  return read_dataset('../datasets/taxi-valid.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "def get_test():\n",
    "  return read_dataset('../datasets/taxi-test.csv', num_epochs=1, mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Refactor the way features are created. </h2>\n",
    "\n",
    "For now, pass these through (same as previous lab).  However, refactoring this way will enable us to break the one-to-one relationship between inputs and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    layers.real_valued_column('pickuplon'),\n",
    "    layers.real_valued_column('pickuplat'),\n",
    "    layers.real_valued_column('dropofflat'),\n",
    "    layers.real_valued_column('dropofflon'),\n",
    "    layers.real_valued_column('passengers'),\n",
    "]\n",
    "\n",
    "feature_cols = INPUT_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create and train the model </h2>\n",
    "\n",
    "Note that we no longer have a num_steps variable.  get_train() specifies a num_epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9413227890>, '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 236.438, step = 1\n",
      "INFO:tensorflow:global_step/sec: 121.869\n",
      "INFO:tensorflow:loss = 83.5303, step = 101 (0.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.34\n",
      "INFO:tensorflow:loss = 87.5894, step = 201 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.912\n",
      "INFO:tensorflow:loss = 94.236, step = 301 (0.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.663\n",
      "INFO:tensorflow:loss = 99.9704, step = 401 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.091\n",
      "INFO:tensorflow:loss = 83.3696, step = 501 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.086\n",
      "INFO:tensorflow:loss = 87.5966, step = 601 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.962\n",
      "INFO:tensorflow:loss = 94.1442, step = 701 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.046\n",
      "INFO:tensorflow:loss = 99.9434, step = 801 (0.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.236\n",
      "INFO:tensorflow:loss = 83.2567, step = 901 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.615\n",
      "INFO:tensorflow:loss = 87.6029, step = 1001 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.474\n",
      "INFO:tensorflow:loss = 94.0733, step = 1101 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.288\n",
      "INFO:tensorflow:loss = 99.9217, step = 1201 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.804\n",
      "INFO:tensorflow:loss = 83.1725, step = 1301 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.154\n",
      "INFO:tensorflow:loss = 87.6084, step = 1401 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.977\n",
      "INFO:tensorflow:loss = 94.0169, step = 1501 (0.777 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 144.958.\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "model = tf.contrib.learn.LinearRegressor(\n",
    "      feature_columns=feature_cols, model_dir='taxi_trained')\n",
    "model.fit(input_fn=get_train());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluate model </h3>\n",
    "\n",
    "As before, evaluate on the validation data.  We'll do the third refactoring (to move the evaluation into the training loop) in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-07-21:19:32\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-1600\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-07-21:19:32\n",
      "INFO:tensorflow:Saving dict for global step 1600: global_step = 1600, loss = 80.1453\n",
      "RMSE on validation dataset = 8.95239162445\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, input_fn):\n",
    "  metrics = model.evaluate(input_fn=input_fn, steps=1)\n",
    "  print 'RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['loss']))\n",
    "print_rmse(model, 'validation', get_valid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
